{
  "4": {
    "inputs": {
      "ckpt_name": "fudukiMix_v15.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "8": {
    "inputs": {
      "samples": ["93", 0],
      "vae": ["60", 2]
    },
    "class_type": "VAEDecode"
  },
  "39": {
    "inputs": {
      "model": ["4", 0],
      "clip": ["4", 1],
      "lora_stack": ["40", 0]
    },
    "class_type": "CR Apply LoRA Stack"
  },
  "40": {
    "inputs": {
      "switch_1": "On",
      "lora_name_1": "miho_v1.safetensors",
      "model_weight_1": 1,
      "clip_weight_1": 1,
      "switch_2": "On",
      "lora_name_2": "NsfwPovAllInOneLoraSdxl-000009.safetensors",
      "model_weight_2": 1,
      "clip_weight_2": 0.4,
      "switch_3": "Off",
      "lora_name_3": "None",
      "model_weight_3": 1,
      "clip_weight_3": 0.4
    },
    "class_type": "CR LoRA Stack"
  },
  "44": {
    "inputs": {
      "image": "20230520004 (8).jpg",
      "choose file to upload": "image"
    },
    "class_type": "LoadImage"
  },
  "46": {
    "inputs": {
      "images": ["70", 0]
    },
    "class_type": "PreviewImage"
  },
  "48": {
    "inputs": {
      "text": "analog film grain,BREAK (TOK:1.5),a photo of japanese girl",
      "clip": ["39", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "49": {
    "inputs": {
      "text": "tattoo,embedding:negativeXL_D, ",
      "clip": ["4", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "55": {
    "inputs": {
      "text": "analog film grain,BREAK (TOK:1.5),a photo of japanese girl",
      "clip": ["60", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "56": {
    "inputs": {
      "text": "tattoo,embedding:negativeXL_D, ",
      "clip": ["60", 1]
    },
    "class_type": "CLIPTextEncode"
  },
  "58": {
    "inputs": {
      "b1": 1,
      "b2": 1.05,
      "s1": 0.9500000000000001,
      "s2": 0.9500000000000001,
      "model": ["39", 0]
    },
    "class_type": "FreeU"
  },
  "60": {
    "inputs": {
      "ckpt_name": "sd_xl_refiner_1.0.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "70": {
    "inputs": {
      "facedetection": "retinaface_resnet50",
      "codeformer_fidelity": 0.5,
      "facerestore_model": ["71", 0],
      "image": ["8", 0]
    },
    "class_type": "FaceRestoreCFWithModel"
  },
  "71": {
    "inputs": {
      "model_name": "GFPGANv1.4.pth"
    },
    "class_type": "FaceRestoreModelLoader"
  },
  "93": {
    "inputs": {
      "noise_seed": 964877563257980,
      "steps": 50,
      "cfg": 10,
      "sampler_name": "dpmpp_2m_sde",
      "scheduler": "karras",
      "base_ratio": 0.8,
      "denoise": 0.55,
      "base_model": ["58", 0],
      "base_positive": ["48", 0],
      "base_negative": ["49", 0],
      "refiner_model": ["60", 0],
      "refiner_positive": ["55", 0],
      "refiner_negative": ["56", 0],
      "latent_image": ["96", 0]
    },
    "class_type": "SeargeSDXLSampler"
  },
  "94": {
    "inputs": {
      "pixels": ["95", 0],
      "vae": ["4", 2]
    },
    "class_type": "VAEEncode"
  },
  "95": {
    "inputs": {
      "upscale_method": "bilinear",
      "megapixels": 0.8,
      "image": ["44", 0]
    },
    "class_type": "ImageScaleToTotalPixels"
  },
  "96": {
    "inputs": {
      "amount": 1,
      "samples": ["94", 0]
    },
    "class_type": "RepeatLatentBatch"
  }
}
